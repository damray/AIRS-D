name: shop-assist
services:
  postgres:
    image: postgres:16-alpine
    container_name: shop-assist-postgres
    env_file:
      - .env.database
    volumes:
      - postgres-data:/var/lib/postgresql/data
      - ./server/init.sql:/docker-entrypoint-initdb.d/init.sql
    ports:
      - "5432:5432"
    networks:
      - shop-network
    restart: unless-stopped
    healthcheck:
      test: ["CMD-SHELL", "pg_isready -U admin -d shop_assist"]
      interval: 10s
      timeout: 5s
      retries: 5

  backend:
    build:
      context: ./server
      dockerfile: Dockerfile
    container_name: shop-assist-backend
    # No public exposure; only inside the network
    expose:
      - "3001"
    env_file:
      - .env.backend
    networks:
      - shop-network
    restart: unless-stopped
    depends_on:
      postgres:
        condition: service_healthy
    healthcheck:
      # Your backend health endpoint is /health
      test: ["CMD", "wget", "--no-verbose", "--tries=1", "--spider", "http://localhost:3001/health"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 15s

  frontend:
    build:
      context: .
      dockerfile: Dockerfile
    container_name: shop-assist-frontend
    # No public exposure; only inside the network
    expose:
      - "80"
    networks:
      - shop-network
    restart: unless-stopped

  # Reverse proxy: single public entrypoint on 80/443
  edge:
    image: nginx:stable-alpine
    container_name: shop-assist-edge
    depends_on:
      backend:
        condition: service_healthy
    ports:
      - "80:80"
      # Uncomment if you terminate TLS here and mount certs below
      # - "443:443"
    volumes:
      - ./nginx/nginx.conf:/etc/nginx/nginx.conf:ro
      # If enabling TLS on edge, mount your certs:
      # - ./nginx/certs/fullchain.pem:/etc/nginx/certs/fullchain.pem:ro
      # - ./nginx/certs/privkey.pem:/etc/nginx/certs/privkey.pem:ro
    networks:
      - shop-network
    restart: unless-stopped

  ollama:
    image: ollama/ollama:latest
    container_name: shop-assist-ollama
    env_file:
      - .env.ollama            # should contain OLLAMA_DEFAULT_MODEL=mistral
    ports:
      - "11434:11434"
    volumes:
      - ollama-data:/root/.ollama
    networks:
      - shop-network
    restart: unless-stopped
    profiles:
      - with-ollama
    healthcheck:
      test: ["CMD-SHELL", "wget -qO- http://localhost:11434/api/version >/dev/null 2>&1 || exit 1"]
      interval: 15s
      timeout: 5s
      retries: 12
      start_period: 60s

  ollama-init:
    image: alpine:3.20
    depends_on:
      ollama:
        condition: service_started
    environment:
      MODEL: "mistral"     # change here if you want another default
    networks:
      - shop-network
    restart: "no"
    command:
      - /bin/sh
      - -c
      - |
        set -eu
        apk add --no-cache curl >/dev/null
        echo "â³ Waiting for Ollama API..."
        for i in $(seq 1 90); do
          if curl -sf http://ollama:11434/api/version >/dev/null 2>&1; then break; fi
          sleep 1
        done
        echo "ðŸ“¦ Pulling model: $MODEL"
        curl -s -H 'Content-Type: application/json' \
             -X POST http://ollama:11434/api/pull \
             -d "{\"name\":\"$MODEL\"}" >/dev/null || true
        echo "âœ… Init done"
    profiles:
      - with-ollama
    
networks:
  shop-network:
    driver: bridge

volumes:
  postgres-data:
    driver: local
  ollama-data:
    driver: local